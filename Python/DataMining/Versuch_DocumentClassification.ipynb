{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Document Classification\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 06.11.2015\n",
    "\n",
    "[Übersicht Versuche im Data Mining Praktikum](http://maucher.pages.mi.hdm-stuttgart.de/ai/page/dm/)\n",
    "\n",
    "## Abgabe:\n",
    "\n",
    "- **Abzugeben ist das Jupyter Notebook mit dem verlangten Implementierungen und den entsprechenden Ausgaben.**\n",
    "- **Das Notebook ist als .ipynb und als .html abzugeben.**\n",
    "- **Klausurelevante Fragen sind Dokument \"Fragenkatalog Datamining\" zu finden.**\n",
    "- Antworten auf Fragen im Notebook, Diskussionen und Beschreibung der Ergebnisse sind optional (aber empfohlen) und werden nicht bewertet.\n",
    "\n",
    "* [Übersicht Data Mining Praktikum](https://maucher.pages.mi.hdm-stuttgart.de/ai/page/dm/)\n",
    "\n",
    "\n",
    "# Einführung\n",
    "\n",
    "## Lernziele:\n",
    "\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Dokumentklassifikation: Klassifikation von Dokumenten, insbesondere Emails und RSS Feed\n",
    "* Naive Bayes Classifier: Weit verbreitete Klassifikationsmethode, welche unter bestimmten Randbedingungen sehr gut skaliert.\n",
    "\n",
    "\n",
    "## Theorie zur Vorbereitung\n",
    "\n",
    "### Parametrische Klassifikation und Naive Bayes Methode\n",
    "\n",
    "Klassifikatoren müssen zu einer gegebenen Eingabe $\\underline{x}$ die zugehörige Klasse $C_i$ bestimmen. Mithilfe der Wahrscheinlichkeitstheorie kann diese Aufgabe wie folgt beschrieben werden: Bestimme für alle möglichen Klassen $C_i$ die bedingte Wahrscheinlichkeit $P(C_i | \\underline{x})$, also die Wahrscheinlichkeit, dass die gegebene Eingabe $\\underline{x}$ in Klasse $C_i$ fällt. Wähle dann die Klasse aus, für welche diese Wahrscheinlichkeit maximal ist.\n",
    "\n",
    "Die Entscheidungsregeln von Klassifikatoren können mit Methoden des \"überwachten Lernens\" aus Trainingsdaten ermittelt werden. Im Fall des **parametrischen Lernens** kann aus den Trainingsdaten die sogenannte **Likelihood-Funktion** $p(\\underline{x} \\mid C_i)$ bestimmt werden. _Anmerkung:_ Allgemein werden mit $p(...)$ kontinuierliche Wahrscheinlichkeitsfunktionen und mit $P(...)$ diskrete Wahrscheinlichkeitswerte bezeichnet. \n",
    "\n",
    "Mithilfe der **Bayes-Formel**\n",
    "$$\n",
    "P(C_i \\mid \\underline{x}) = \\frac{p(\\underline{x} \\mid C_i) \\cdot P(C_i)}{p(\\underline{x})}\n",
    "$$\n",
    "\n",
    "kann aus der Likelihood die **a-posteriori-Wahrscheinlichkeit $P(C_i \\mid \\underline{x})$** berechnet werden. Darin wird $P(C_i)$ die **a-priori-Wahrscheinlichkeit** und $p(\\underline{x})$ die **Evidenz** genannt. Die a-priori-Wahrscheinlichkeit kann ebenfalls aus den Trainingsdaten ermittelt werden. Die Evidenz ist für die Klassifikationsentscheidung nicht relevant, da sie für alle Klassen $C_i$ gleich groß ist.\n",
    "\n",
    "Die Berechnung der Likelihood-Funktion $p(\\underline{x} \\mid C_i)$ ist dann sehr aufwendig, wenn $\\underline{x}=(x_1,x_2,\\ldots,x_Z)$ ein Vektor von voneinander abhängigen Variablen $x_i$ ist. Bei der **Naive Bayes Classification** wird jedoch von der vereinfachenden Annahme ausgegangen, dass die Eingabevariabeln $x_i$ voneinander unabhängig sind. Dann vereinfacht sich die bedingte Verbundwahrscheinlichkeits-Funktion $p(x_1,x_2,\\ldots,x_Z \\mid C_i)$ zu:\n",
    "\n",
    "$$\n",
    "p(x_1,x_2,\\ldots,x_Z \\mid C_i)=\\prod\\limits_{j=1}^Z p(x_j | C_i)\n",
    "$$\n",
    "\n",
    "### Anwendung der Naive Bayes Methode in der Dokumentklassifikation\n",
    "\n",
    "Auf der rechten Seite der vorigen Gleichung stehen nur noch von den jeweils anderen Variablen unabhängige bedingte Wahrscheinlichkeiten. Im Fall der Dokumentklassifikation sind die einzelnen Worte die Variablen, d.h. ein Ausdruck der Form $P(x_j | C_i)$ gibt an mit welcher Wahrscheinlichkeit ein Wort $x_j=w$ in einem Dokument der Klasse $C_i$ vorkommt. \n",
    "Die Menge aller Variablen $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ ist dann die Menge aller Wörter im Dokument. Damit gibt die linke Seite in der oben gegebenen Gleichung die *Wahrscheinlichkeit, dass die Wörter $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ in einem Dokument der Klasse $C_i$ vorkommen*, an.\n",
    "\n",
    "Für jedes Wort _w_ wird aus den Trainingsdaten die Wahrscheinlichkeit $P(w|G)$, mit der das Wort in Dokumenten der Kategorie _Good_ und die Wahrscheinlichkeit $P(w|B)$ mit der das Wort in Dokumenten der Kategorie _Bad_ auftaucht ermittelt. Trainingsdokumente werden in der Form\n",
    "\n",
    "$$\n",
    "tD=(String,Category)\n",
    "$$\n",
    "eingegeben. \n",
    "\n",
    "Wenn \n",
    "\n",
    "* mit der Variable $fc(w,cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ in denen das Wort $w$ enthalten ist\n",
    "* mit der Variable $cc(cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ \n",
    "\n",
    "gezählt wird, dann ist \n",
    "\n",
    "$$\n",
    "P(w|G)=\\frac{fc(w,G)}{cc(G)} \\quad \\quad P(w|B)=\\frac{fc(w,B)}{cc(B)}.\n",
    "$$\n",
    "\n",
    "Wird nun nach der Eingabe von $L$ Trainingsdokumenten ein neu zu klassifizierendes Dokument $D$ eingegeben und sei $W(D)$ die Menge aller Wörter in $D$, dann berechnen sich unter der Annahme, dass die Worte in $W(D)$ voneinander unabhängig sind (naive Bayes Annahme) die a-posteriori Wahrscheinlichkeiten zu:\n",
    "\n",
    "$$\n",
    "P(G|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | G) \\right) \\cdot P(G)}{p(D)}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | B) \\right) \\cdot P(B)}{p(D)}.\n",
    "$$\n",
    "\n",
    "Die hierfür notwendigen a-priori-Wahrscheinlichkeiten berechnen sich zu \n",
    "\n",
    "$$\n",
    "P(G)=\\frac{cc(G)}{L}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B)=\\frac{cc(B)}{L}\n",
    "$$\n",
    "\n",
    "Die Evidenz $p(D)$ beeinflusst die Entscheidung nicht und kann deshalb ignoriert werden.\n",
    "\n",
    "\n",
    "## Vor dem Versuch zu klärende Fragen\n",
    "\n",
    "\n",
    "1. Wie wird ein Naive Bayes Classifier trainiert? Was muss beim Training für die spätere Klassifikation abgespeichert werden?\n",
    "2. Wie teilt ein Naiver Bayes Classifier ein neues Dokument ein?\n",
    "3. Welche naive Annahme liegt dem Bayes Classifier zugrunde? Ist diese Annahme im Fall der Dokumentklassifikation tatsächlich gegeben?\n",
    "4. Betrachten Sie die Formeln für die Berechnung von $P(G|D)$ und $P(B|D)$. Welches Problem stellt sich ein, wenn in der Menge $W(D)$ ein Wort vorkommt, das nicht in den Trainingsdaten der Kategorie $G$ vorkommt und ein anderes Wort aus $W(D)$ nicht in den Trainingsdaten der Kategorie $B$ enthalten ist? Wie könnte dieses Problem gelöst werden? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Naive Bayes Classifier wird durch gelabelte Beispiele trainiert. Die Häufigkeit der Klassen und die Häufigkeit der Wörter pro Klasse werden abgespeichert.\n",
    "2. Es schaut sich das Dokument an, sucht sich die Wahrscheinlichkeiten für die Variablen im Dokument und rechnet dann die Wahrscheinlichkeit aus. Das Dokument gehört in die Klasse mit höherer Wahrscheinlichkeit rein.\n",
    "3. Beim Bayes Classifier wird es angenommen, dass die Variabeln unabhängig von einander sind. Nein, aber die Wörter werden unabhängig von einander in unserem Versuch betrachtet.\n",
    "4. Wenn das Wort nicht in den Trainingsdaten vorkommt, wird es ein Null-Faktor-Problem geben und der Classifier kann das Dokument nicht Kategorisieren. Dies kann durch smoothing vermieden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Feature Extraction/ -Selection\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie eine Funktion *getwords(doc)*, der ein beliebiges Dokument in Form einer String-Variablen übergeben wird. In der Funktion soll der String in seine Wörter zerlegt und jedes Wort in _lowercase_ transformiert werden. Wörter, die weniger als eine untere Grenze von Zeichen (z.B. 3) oder mehr als eine obere Grenze von Zeichen (z.B. 20) enthalten, sollen ignoriert werden. Die Funktion soll ein dictionary zurückgeben, dessen _Keys_ die Wörter sind. Die _Values_ sollen für jedes Wort zunächst auf $1$ gesetzt werden.\n",
    "\n",
    "**Tipp:** Benutzen Sie für die Zerlegung des Strings und für die Darstellung aller Wörter mit ausschließlich kleinen Buchstaben die Funktionen *split(), strip('sep')* und *lower()* der Klasse *String*.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwords(doc):\n",
    "    words = doc.split()\n",
    "    word_dict = {}\n",
    "    for word in words:\n",
    "        word = word.strip(',.:!?)(')\n",
    "        if len(word) >= 3 and len(word)<=20:\n",
    "            word_dict[word.lower()]=1\n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 1, 'haha': 1, 'hehe': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getwords(\"Test 1, 2, 3: haha hehe, hehe. abcdefghijklmnopqrstuvwxyz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classifier\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie den Naive Bayes Classifier für die Dokumentklassifikation. Es bietet sich an die Funktionalität des Klassifikators und das vom Klassifikator gelernte Wissen in einer Instanz einer Klasse _Classifier_ zu kapseln. In diesem Fall kann wie folgt vorgegangen werden:\n",
    "\n",
    "* Im Konstruktor der Klasse wird je ein Dictionary für die Instanzvariablen _fc_ und _cc_ (siehe oben) initialisiert. Dabei ist _fc_ ein verschachteltes Dictionary. Seine Keys sind die bisher gelernten Worte, die Values sind wiederum Dictionaries, deren Keys die Kategorien _Good_ und _Bad_ sind und deren Values zählen wie häufig das Wort bisher in Dokumenten der jeweiligen Kategorie auftrat. Das Dictionary _cc_ hat als Keys die Kategorien _Good_ und _Bad_. Die Values zählen wie häufig Dokumente der jeweiligen Kategorien bisher auftraten.\n",
    "* Im Konstruktor wird ferner der Instanzvariablen _getfeatures_ die Funktion *getwords()* übergeben. Die Funktion _getwords()_ wurde bereits zuvor ausserhalb der Klasse definiert. Sinn dieses Vorgehens ist, dass andere Varianten um Merkmale aus Dokumenten zu extrahieren denkbar sind. Diese Varianten könnten dann ähnlich wie die *getwords()*-Funktion ausserhalb der Klasse definiert und beim Anlegen eines *Classifier*-Objekts der Instanzvariablen _getfeatures_ übergeben werden.  \n",
    "* Der Methode _incf(self,f,cat)_ wird ein Wort _f_ und die zugehörige Kategorie _cat_ des Dokuments in welchem es auftrat übergeben. In der Methode wird der *fc*-Zähler angepasst.\n",
    "* Der Methode _incc(self,cat)_ wird die Kategorie _cat_ des gerade eingelesenen Dokuments übergeben. In der Methode wird der *cc*-Zähler angepasst.\n",
    "* Die Methode _fcount(self,f,cat)_ gibt die Häufigkeit des Worts _f_ in den Dokumenten der Kategorie _cat_ zurück.\n",
    "* Die Methode _catcount(self,cat)_ gibt die Anzahl der Dokumente in der Kategorie _cat_ zurück.\n",
    "* Die Methode _totalcount(self)_ gibt die Anzahl aller Dokumente zurück.\n",
    "* Der Methode _train(self,item,cat)_ wird ein neues Trainingselement, bestehend aus der Betreffzeile (*item*) und der entsprechenden Kategorisierung (*cat*) übergeben. Der String _item_ wird mit der Instanzmethode _getfeatures_ (Diese referenziert *getwords()*) in Worte zerlegt. Für jedes einzelne Wort wird dann *incf(self,f,cat)* aufgerufen. Ausserdem wird für das neue Trainingsdokument die Methode _incc(self,cat)_ aufgerufen.\n",
    "* Die Methode _fprob(self,f,cat)_ berechnet die bedingte Wahrscheinlichkeit $P(f | cat)$ des Wortes _f_ in der Kategorie _cat_ entsprechend der oben angegebenen Formeln, indem sie den aktuellen Stand des Zählers _fc(f,cat)_ durch den aktuellen Stand des Zählers _cc(cat)_ teilt.   \n",
    "* Die Methode _fprob(self,f,cat)_ liefert evtl. ungewollt extreme Ergebnisse, wenn noch wenig Wörter im Klassifizierer verbucht sind. Kommt z.B. ein Wort erst einmal in den Trainingsdaten vor, so wird seine Auftrittswahrscheinlichkeit in der Kategorie in welcher es nicht vorkommt gleich 0 sein. Um extreme Wahrscheinlichkeitswerte im Fall noch selten vorkommender Werte zu vermeiden, soll zusätzlich zur Methode _fprob(self,f,cat)_ die Methode _weightedprob(self,f,cat)_ implementiert und angewandt werden. Der von ihr zurückgegebene Wahrscheinlichkeitswert könnte z.B. wie folgt berechnet werden:$$wprob=\\frac{initprob+count \\cdot fprob(self,f,cat)}{1+count},$$ wobei $initprob$ ein initialer Wahrscheinlichkeitswert (z.B. 0.5) ist, welcher zurückgegeben werden soll, wenn das Wort noch nicht in den Trainingsdaten aufgetaucht ist. Die Variable $count$ zählt wie oft das Wort $f$ bisher in den Trainingsdaten auftrat. Wie zu erkennen ist, nimmt der Einfluss der initialen Wahrscheinlichkeit ab, je häufiger das Wort in den Trainingsdaten auftrat.\n",
    "* Nach dem Training soll ein beliebiges neues Dokument (Text-String) eingegeben werden können. Für dieses soll mit der Methode _prob(self,item,cat)_ die a-posteriori-Wahrscheinlichkeit $P(cat|item)$ (Aufgrund der Vernachlässigung der Evidenz handelt es sich hierbei genaugenommen um das Produkt aus a-posteriori-Wahrscheinlichkeit und Evidenz), mit der das Dokument _item_ in die Kategorie _cat_ fällt berechnet werden. Innerhalb der Methode _prob(self,item,cat)_ soll zunächst die Methode _weightedprob(self,f,cat)_ für alle Wörter $f$ im Dokument _item_ aufgerufen werden. Die jeweiligen Rückgabewerte von _weightedprob(self,f,cat)_ werden multipliziert. Das Produkt der Rückgabewerte von _weightedprob(self,f,cat)_ über alle Wörter $f$ im Dokument muss schließlich noch mit der a-priori Wahrscheinlichkeit $P(G)$ bzw. $P(B)$ entsprechend der oben aufgeführten Formeln multipliziert werden. Das Resultat des Produkts wird an das aufrufende Programm zurück gegeben, die Evidenz wird also vernachlässigt (wie oben begründet).\n",
    "\n",
    "\n",
    "\n",
    "Ein Dokument _item_ wird schließlich der Kategorie _cat_ zugeteilt, für welche die Funktion _prob(self,item,cat)_ den höheren Wert zurück gibt. Da die Rückgabewerte in der Regel sehr klein sind, werden in der Regel folgende Werte angezeigt:\n",
    "* Wenn mit $g$ der Rückgabewert von _prob(self,item,cat=G)_ und mit $b$ der Rückgabewert von _prob(self,item,cat=B)_ bezeichnet wird dann ist die Wahrscheinlichkeit, dass $item$ in die Kategorie $G$ fällt, gleich:\n",
    "$$\n",
    "\\frac{g}{g+b}\n",
    "$$\n",
    "* und die Wahrscheinlichkeit, dass $item$ in die Kategorie $B$ fällt, gleich:\n",
    "$$\n",
    "\\frac{b}{g+b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class nbClassifier:\n",
    "    def __init__(self, getfeatures):\n",
    "        self.cc = {}\n",
    "        self.fc = {}\n",
    "        self.getfeatures= getfeatures\n",
    "        self.printWP = False\n",
    "        self.printClassProb = False\n",
    "        \n",
    "    def allowPrint(self, weightedProbas, classProbas):\n",
    "        self.printWP = weightedProbas\n",
    "        self.printClassProb = classProbas \n",
    "        \n",
    "    def incf(self,f,cat):\n",
    "        \n",
    "        if self.fc.get(f) is None :    \n",
    "            self.fc[f]= {cat: 1}\n",
    "            return\n",
    "        \n",
    "        if self.fc[f].get(cat) is None or not isinstance(self.fc[f].get(cat), int):\n",
    "            self.fc[f][cat]=1\n",
    "            return\n",
    "        \n",
    "        self.fc[f][cat]+=1\n",
    "    \n",
    "    \n",
    "    def incc(self,cat):\n",
    "        if self.cc.get(cat) is None or not isinstance(self.cc.get(cat), int) :\n",
    "            self.cc[cat] = 1\n",
    "            return\n",
    "        self.cc[cat] +=1\n",
    "        \n",
    "    def fcount(self,f,cat):\n",
    "        if self.fc.get(f) is None:\n",
    "            return 0\n",
    "        if self.fc[f].get(cat) is None:\n",
    "            return 0\n",
    "            \n",
    "        return self.fc[f][cat]\n",
    "    \n",
    "    def catcount(self,cat):\n",
    "        if self.cc.get(cat) is None:\n",
    "            return 0\n",
    "        return self.cc[cat]\n",
    "    \n",
    "    def totalcount(self):\n",
    "        catsum = 0\n",
    "        for cats in self.cc:\n",
    "            catsum += self.catcount(cats)\n",
    "        return catsum\n",
    "    \n",
    "    def train(self, item, cat):\n",
    "        self.incc(cat)\n",
    "        worddict = self.getfeatures(item)\n",
    "        \n",
    "        for word in worddict:\n",
    "            self.incf(word,cat)\n",
    "            \n",
    "    def fprob(self,f,cat):\n",
    "        return self.fcount(f,cat) / self.catcount(cat)\n",
    "        \n",
    "    def weightedprob(self,f,cat):\n",
    "        initprob = 0\n",
    "        wordcount = 0\n",
    "        tfprob = self.fprob(f,cat)\n",
    "        for cats in self.cc:\n",
    "            wordcount  += self.fcount(f,cats)\n",
    "        catsum=0\n",
    "        for cats in self.cc:\n",
    "            catsum += 1\n",
    "        initprob = 1/catsum\n",
    "        wprob = (initprob + wordcount * tfprob) / (1+wordcount)\n",
    "        if self.printWP:\n",
    "            print(f\"{f}| {cat}: {wprob}\")\n",
    "        return wprob\n",
    "        \n",
    "        \n",
    "    def prob(self,item,cat):\n",
    "        worddict= self.getfeatures(item)\n",
    "        proba = 1\n",
    "        for word in worddict:\n",
    "            proba *= self.weightedprob(word,cat)\n",
    "        \n",
    "        return proba * (self.catcount(cat)/self.totalcount())\n",
    "    \n",
    "    def classify(self,item):\n",
    "        catlist = []\n",
    "        for cat in self.cc:\n",
    "            catlist.append((cat,self.prob(item,cat)))\n",
    "        \n",
    "        probsum = 0 \n",
    "        for cat in catlist:\n",
    "            probsum += cat[1]\n",
    "        if self.printClassProb:\n",
    "            print(\"\\nClass probabilities:\\n\")\n",
    "        catprob=[]\n",
    "        for cat,prob in catlist:\n",
    "            catprob.append((cat,prob/probsum)) \n",
    "        if self.printClassProb:\n",
    "            for e in catprob:     \n",
    "                print(f\"{e[0]}: {e[1]}\\n\")\n",
    "        catprob = sorted(catprob,reverse = True ,key=lambda x: x[1])\n",
    "        return catprob[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "**Aufgabe:**\n",
    "Instanzieren Sie ein Objekt der Klasse _Classifier_ und übergeben Sie der _train()_ Methode dieser Klasse mindestens 8 kategorisierte Dokumente (Betreffzeilen als Stringvariablen zusammen mit der Kategorie Good oder Bad). Definieren Sie dann ein beliebig neues Dokument und berechnen Sie für dieses die Kategorie, in welches es mit größter Wahrscheinlichkeit fällt. Benutzen Sie für den Test das in der\n",
    "[NLP Vorlesung Document Classification](https://griesshaber.pages.mi.hdm-stuttgart.de/nlp/06classification/07classificationNaiveBayes.html)\n",
    "ausführlich beschriebene Beispiel zu implementieren. Berechnen Sie die Klassifikatorausgabe des Satzes _the money jumps_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the| Good: 0.7\n",
      "money| Good: 0.16666666666666666\n",
      "jumps| Good: 0.5\n",
      "the| Bad: 0.3\n",
      "money| Bad: 0.5\n",
      "jumps| Bad: 0.16666666666666666\n",
      "\n",
      "Class probabilities:\n",
      "\n",
      "Good: 0.7\n",
      "\n",
      "Bad: 0.3\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Good'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testnbc = nbClassifier(getwords)\n",
    "testnbc.allowPrint(True, True)\n",
    "\n",
    "trainingdataGood = [\"nobody owns the water\", \"the quick rabbit jumps fences\", \"the quick brown fox jumps\", \"next meeting is at night\"]\n",
    "trainingdataBad = [\"buy pharmaceuticals now\", \"make quick money at the online casino\", \"meeting with your superstar\", \"money like water\"]\n",
    "\n",
    "for data in trainingdataGood:\n",
    "    testnbc.train(data,\"Good\")\n",
    "\n",
    "for data in trainingdataBad:\n",
    "    testnbc.train(data,\"Bad\")\n",
    "\n",
    "testnbc.classify(\"the money jumps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nobody| Good: 0.375\n",
      "now| Good: 0.25\n",
      "money| Good: 0.16666666666666666\n",
      "nobody| Bad: 0.25\n",
      "now| Bad: 0.375\n",
      "money| Bad: 0.5\n",
      "\n",
      "Class probabilities:\n",
      "\n",
      "Good: 0.25\n",
      "\n",
      "Bad: 0.75\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bad'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testnbc.classify(\"nobody now money\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc = nbClassifier(getwords)\n",
    "nbc.allowPrint(False,True)\n",
    "\n",
    "trainingBad= [\"Act now! Your last chance to claim the prize\",\"Guaranteed more Money to win. Urgent!\",\"Your chance to win very big prizes\",\"Claim your Money now!\"]\n",
    "trainingMom= [\"Hey Sweety, hope you like this meem!\",\"Sweety, its very urgent, we gotta talk about this!\", \"Hope youre doing very well!\", \"I found some very funny meems :)\"]\n",
    "trainingGood = [\"A big Win for our local Sports Team!\", \"Reminder for Doctors Appointment\", \"Yesterdays team meeting protocoll\", \"Big Changes: next meetings topics\"]\n",
    "\n",
    "for data in trainingGood:\n",
    "    nbc.train(data,\"Good\")\n",
    "\n",
    "for data in trainingBad:\n",
    "    nbc.train(data,\"Bad\")\n",
    "\n",
    "for data in trainingMom:\n",
    "    nbc.train(data,\"Mom\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class probabilities:\n",
      "\n",
      "Good: 0.7777777777777777\n",
      "\n",
      "Bad: 0.11111111111111113\n",
      "\n",
      "Mom: 0.11111111111111113\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Good'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbc.classify(\"Team reminder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class probabilities:\n",
      "\n",
      "Good: 0.003508771929824561\n",
      "\n",
      "Bad: 0.014035087719298244\n",
      "\n",
      "Mom: 0.9824561403508772\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mom'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbc.classify(\"Sweety this meem was very mean :( \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class probabilities:\n",
      "\n",
      "Good: 0.004585979090500928\n",
      "\n",
      "Bad: 0.9951574626387018\n",
      "\n",
      "Mom: 0.0002565582707972548\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bad'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbc.classify(\"Now is your Chance! Big prizes to win\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation von RSS Newsfeeds\n",
    "Mit dem unten gegebenen Skript werden Nachrichten verschiedener Newsserver geladen und als String abgespeichert.\n",
    "\n",
    "**Aufgaben:**\n",
    "1. Trainieren Sie Ihren Naive Bayes Classifier mit allen Nachrichten der in den Listen _trainTech_ und _trainNonTech_ definierten Servern. Weisen Sie für das Training allen Nachrichten aus _trainTech_ die Kategorie _Tech_ und allen Nachrichten aus _trainNonTech_ die Kategorie _NonTech_ zu.\n",
    "2. Nach dem Training sollen alle Nachrichten aus der Liste _test_ vom Naive Bayes Classifier automatisch klassifiziert werden. Gehen Sie davon aus, dass alle Nachrichten von [http://rss.golem.de/rss.php?r=sw&feed=RSS0.91](http://rss.golem.de/rss.php?r=sw&feed=RSS0.91) tatsächlich von der Kategorie _Tech_ sind und alle Nachrichten von den beiden anderen Servern in der Liste _test_ von der Kategorie _NonTech_ sind. Bestimmen Sie die _Konfusionsmatrix_ und die _Accuracy_ sowie für beide Klassen _Precision, Recall_ und _F1-Score_. Diese Qualitätsmetriken sind z.B. in [NLP Vorlesung Document Classification](https://griesshaber.pages.mi.hdm-stuttgart.de/nlp/06classification/06classificationMetrics.html) definiert.\n",
    "3. Diskutieren Sie das Ergebnis\n",
    "4. Wie könnte die Klassifikationsgüte durch Modifikation der *getwords()*-Methode verbessert werden? Implementieren Sie diesen Ansatz und vergleichen Sie das Ergebnis mit dem des ersten Ansatzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of used trainings samples in categorie tech 226\n",
      "Number of used trainings samples in categorie notech 112\n",
      "Number of used test samples 85\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "def countFeed(feedList, title, should_print=False):\n",
    "    if should_print:\n",
    "        print(f\"--------------------News from {title}------------------------\")\n",
    "    count = 0\n",
    "    for feed in feedList:\n",
    "        if should_print:\n",
    "            print()\n",
    "            print(\"*\"*30)\n",
    "            print(feed)\n",
    "        f=feedparser.parse(feed)\n",
    "        for e in f.entries:\n",
    "            if hasattr(e, 'title') and hasattr(e, 'description'):\n",
    "                if should_print:\n",
    "                    print('\\n---------------------------')\n",
    "                fulltext=stripHTML(e.title+' '+e.description)\n",
    "                if should_print:\n",
    "                    print(fulltext)\n",
    "                count += 1\n",
    "    if should_print:\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "    return count\n",
    "\n",
    "def stripHTML(h):\n",
    "    p=''\n",
    "    s=0\n",
    "    for c in h:\n",
    "        if c=='<': \n",
    "            s=1\n",
    "        elif c=='>':\n",
    "            s=0\n",
    "            p+=' '\n",
    "        elif s==0:\n",
    "            p+=c\n",
    "    return p\n",
    "\n",
    "\n",
    "trainTech=['https://www.chip.de/rss/rss_ssh_news.xml',\n",
    "           #'http://feeds.feedburner.com/netzwelt',\n",
    "           'https://www.t-online.de/digital/feed.rss',\n",
    "           'http://www.computerbild.de/rssfeed_2261.xml?node=13',\n",
    "           'http://www.heise.de/newsticker/heise-top-atom.xml']\n",
    "\n",
    "trainNonTech=['http://newsfeed.zeit.de/index',\n",
    "              'http://newsfeed.zeit.de/wirtschaft/index',\n",
    "              'http://www.welt.de/politik/?service=Rss',\n",
    "              'http://www.spiegel.de/schlagzeilen/tops/index.rss',\n",
    "              'https://rss.sueddeutsche.de/alles',\n",
    "              'http://www.faz.net/rss/aktuell/']\n",
    "\n",
    "test=['http://rss.golem.de/rss.php?r=sw&feed=RSS0.91',\n",
    "      'http://newsfeed.zeit.de/politik/index',  \n",
    "      'http://www.welt.de/?service=Rss']\n",
    "\n",
    "countnews={}\n",
    "countnews['tech']=countFeed(trainTech, 'trainTech', should_print=False)\n",
    "countnews['nontech']=countFeed(trainNonTech, 'trainNonTech')\n",
    "countnews['test']=countFeed(test, 'test')\n",
    "\n",
    "print('Number of used trainings samples in categorie tech',countnews['tech'])\n",
    "print('Number of used trainings samples in categorie notech',countnews['nontech'])\n",
    "print('Number of used test samples',countnews['test'])\n",
    "print('--'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsNbc = nbClassifier(getwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newsToStringList(feedList,cat):\n",
    "    returnList = []\n",
    "    for feed in feedList:\n",
    "        f=feedparser.parse(feed)\n",
    "        for e in f.entries:\n",
    "            if hasattr(e, 'title') and hasattr(e, 'description'):\n",
    "                text = f\"{stripHTML(e.title+' '+e.description)}\"\n",
    "                returnList.append((text,cat))\n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNewsTech = newsToStringList(trainTech,\"Tech\")\n",
    "trainNewsNonTech = newsToStringList(trainNonTech,\"NonTech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBatch(textCatList,classifier):\n",
    "    for text,cat in textCatList:\n",
    "        classifier.train(text,cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBatch(trainNewsTech, newsNbc)\n",
    "trainBatch(trainNewsNonTech,newsNbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNewsTech = newsToStringList([test[0]],\"Tech\")\n",
    "testNewsNonTech = newsToStringList([test[1],test[2]],\"NonTech\")\n",
    "testListList = [testNewsTech,testNewsNonTech]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMetricDict(classifier,testListList):\n",
    "    classifier.allowPrint(False,False)\n",
    "    metricDict = {}\n",
    "    for testList in testListList: \n",
    "        for test,preCat in testList:\n",
    "            cat=preCat.strip(\"!\")\n",
    "            falseCat= \"!\"+cat\n",
    "            if classifier.classify(test) == cat:\n",
    "                if metricDict.get(cat) is None:\n",
    "                    metricDict[cat]=1\n",
    "                else:\n",
    "                    metricDict[cat]+=1\n",
    "            else:\n",
    "                if metricDict.get(falseCat) is None:\n",
    "                    metricDict[falseCat]=1\n",
    "                else:\n",
    "                    metricDict[falseCat]+=1\n",
    "    return metricDict\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tech': 27, '!Tech': 13, 'NonTech': 30, '!NonTech': 15}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricDict = createMetricDict(newsNbc,testListList)\n",
    "metricDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printConfMat(metricDict):\n",
    "    keys = []\n",
    "    for key in metricDict:\n",
    "        keys.append(key)\n",
    "    l1 = max(len(keys[3]),5)\n",
    "    l2 = max(len(keys[0]),5)\n",
    "    l3 = max(len(keys[1]),5)\n",
    "    print (\"{:<15} Predicted Labels \\n\".format(\" \"))\n",
    "    print (\"{:<15}{:<10}|{:<6} |{:<6}\".format(\" \",\" \",keys[0],keys[2]))\n",
    "    print('--'*30)\n",
    "    print (\"{:<15}{:<10}| {:<6}|{:<6}\".format(\"True Label\",keys[0],metricDict[keys[0]],metricDict[keys[3]]))\n",
    "    print(\" \"*15+'-'*45)\n",
    "    \n",
    "    print (\"{:<15}{:<10}| {:<6}|{:<6}\".format(\" \",keys[2],metricDict[keys[1]],metricDict[keys[2]]))\n",
    "    print('--'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(metricDict):\n",
    "    datacount=0\n",
    "    hits=0\n",
    "    for key in metricDict:\n",
    "        if not key.startswith(\"!\"):\n",
    "            hits += metricDict.get(key)\n",
    "        datacount += metricDict.get(key)\n",
    "    return hits/datacount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecall(metricDict,printResult=True):\n",
    "    keys = list(metricDict.keys())\n",
    "    recallList = []\n",
    "    recallList.append((keys[0],metricDict.get(keys[0])/(metricDict.get(keys[0])+metricDict.get(keys[3]))))\n",
    "    recallList.append((keys[2],metricDict.get(keys[2])/(metricDict.get(keys[2])+metricDict.get(keys[1]))))\n",
    "    if printResult:\n",
    "        print(f\"Recall {recallList[0][0]}: {recallList[0][1]}\")\n",
    "        print(f\"Recall {recallList[1][0]}: {recallList[1][1]}\")   \n",
    "    return recallList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrecision(metricDict, printResult = True):\n",
    "    keys = list(metricDict.keys())\n",
    "    precList = []\n",
    "    precList.append((keys[0],metricDict.get(keys[0])/(metricDict.get(keys[0])+metricDict.get(keys[1]))))\n",
    "    precList.append((keys[2],metricDict.get(keys[2])/(metricDict.get(keys[2])+metricDict.get(keys[3]))))\n",
    "    if printResult:\n",
    "        print(f\"Precision {precList[0][0]}: {precList[0][1]}\")\n",
    "        print(f\"Precision {precList[1][0]}: {precList[1][1]}\")\n",
    "    return precList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getF1List(metricDict, printResult = True):\n",
    "    accuracy = getAccuracy(metricDict)\n",
    "    precList = getPrecision(metricDict,False)\n",
    "    f1List=[]\n",
    "    for cat,prec in precList:\n",
    "        f1 = 2*(accuracy*prec)/(accuracy+prec)\n",
    "        if printResult:\n",
    "            print(f\"F1 {cat}: {f1}\")\n",
    "        f1List.append((cat,f1))\n",
    "    return f1List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allMetrics(metricDict):\n",
    "    recall = getRecall(metricDict,False)\n",
    "    precision = getPrecision(metricDict,False)\n",
    "    f1_score = getF1List(metricDict,False)\n",
    "    print(\"Confusion Matrix:\\n\")\n",
    "    printConfMat(metricDict)\n",
    "    print(\"__\"*30)\n",
    "    print(f\"\\nAccuracy: {getAccuracy(metricDict)}\\n\" + \"__\"*30)\n",
    "    print(f\"\\nRecall:\\n\\n{recall[0][0]}: {recall[0][1]}\\n{recall[1][0]}: {recall[1][1]}\\n\" + \"__\"*30)\n",
    "    print(f\"\\nPrecision:\\n\\n{precision[0][0]}: {precision[0][1]}\\n{precision[1][0]}: {precision[1][1]}\\n\" + \"__\"*30)\n",
    "    print(f\"\\nF1-Score:\\n\\n{f1_score[0][0]}: {f1_score[0][1]}\\n{f1_score[1][0]}: {f1_score[1][1]}\\n\" + \"__\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "                Predicted Labels \n",
      "\n",
      "                         |Tech   |NonTech\n",
      "------------------------------------------------------------\n",
      "True Label     Tech      | 27    |15    \n",
      "               ---------------------------------------------\n",
      "               NonTech   | 13    |30    \n",
      "------------------------------------------------------------\n",
      "____________________________________________________________\n",
      "\n",
      "Accuracy: 0.6705882352941176\n",
      "____________________________________________________________\n",
      "\n",
      "Recall:\n",
      "\n",
      "Tech: 0.6428571428571429\n",
      "NonTech: 0.6976744186046512\n",
      "____________________________________________________________\n",
      "\n",
      "Precision:\n",
      "\n",
      "Tech: 0.675\n",
      "NonTech: 0.6666666666666666\n",
      "____________________________________________________________\n",
      "\n",
      "F1-Score:\n",
      "\n",
      "Tech: 0.6727868852459016\n",
      "NonTech: 0.6686217008797654\n",
      "____________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "allMetrics(metricDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "3:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da 29 Tech-Artikel und 56 NonTech-Artikel in den Test-Daten waren, kann dieser Mengenunterschied der Accuracy die Aussagekraft nehmen. \n",
    "Der Classifier hat eine deutlich höhere Präzision und einen niedrigeren Recall bei NonTech-Artikeln, was bedeutet, er klassifiziert Artikel eher zu Tech als zu Non-Tech. Nur ein drittel der Testdaten waren tatsächlich Tech und der Classifier ging davon aus, dass fast die hälfte Tech ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('german')\n",
    "special_characters = [*\",.:!?)(-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBetterWords(doc):\n",
    "    \n",
    "    for char in special_characters:\n",
    "        doc = doc.replace(char,\" \")\n",
    "\n",
    "    words = doc.split()\n",
    "    word_dict = {}\n",
    "    for word in words:\n",
    "        word = word.strip(',.:!?)(')\n",
    "        if len(word) >= 3 and len(word)<=20:\n",
    "            if word not in stop_words:\n",
    "                word_dict[word.lower()]=1\n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "betterClassifier = nbClassifier(getBetterWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBatch(trainNewsTech, betterClassifier)\n",
    "trainBatch(trainNewsNonTech, betterClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricDict2 = createMetricDict(betterClassifier,testListList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "                Predicted Labels \n",
      "\n",
      "                         |Tech   |NonTech\n",
      "------------------------------------------------------------\n",
      "True Label     Tech      | 33    |12    \n",
      "               ---------------------------------------------\n",
      "               NonTech   | 7     |33    \n",
      "------------------------------------------------------------\n",
      "____________________________________________________________\n",
      "\n",
      "Accuracy: 0.7764705882352941\n",
      "____________________________________________________________\n",
      "\n",
      "Recall:\n",
      "\n",
      "Tech: 0.7333333333333333\n",
      "NonTech: 0.825\n",
      "____________________________________________________________\n",
      "\n",
      "Precision:\n",
      "\n",
      "Tech: 0.825\n",
      "NonTech: 0.7333333333333333\n",
      "____________________________________________________________\n",
      "\n",
      "F1-Score:\n",
      "\n",
      "Tech: 0.8\n",
      "NonTech: 0.7542857142857142\n",
      "____________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "allMetrics(metricDict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem die Stoppwörter und Sonderzeichen entfernt wurden, kann eine Erhöhung der Accuracy beobachtet werden. Der Classifier hat mit der Funktion getBetterWords() eine höhere Präzision für Techseiten. Für NonTech-Artikel fällt diese aber etwas niedriger als mit getwords() aus.\n",
    "Die Neigung des Classifiers ist nun umgekehrt zu dem vorherigen, aber deutlich gemäßigter.\n",
    "Der F1-Score ist eben für beide Klassen höher."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
